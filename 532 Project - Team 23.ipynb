{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Members: Arhum Zafar, Rebecca Mercer, Abhiram Koganti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "A Convolutional Neural Network (CNN) is a deep learning algorithm applied for visual image analysis. CNNs use pooling and convolution in order to produce classifications. Pooling reduces the resolution of the image by representing it in a smaller matrix. Convolution is used to detect features (such as “edges”) so that in large images it can perform more quickly than a deep network. These steps of feature extraction lead to quicker and less time/space consuming classification. CNNs have a wide range of applications in image and video recognition, image classification, natural language processing, and more. The intent of this project is to introduce the CNN algorithm and its fundamentals. \n",
    "\n",
    "#### Learning Objectives\n",
    "- Students will understand the motivation behind convolutional neural networks.\n",
    "- Students will be able to perform the mathematics of convolution.\n",
    "- Students will have exposure to the general architecture of convolutional neural networks.\n",
    "\n",
    "Our background will lead students through the steps of a CNN from input through feature extraction to classification. We will focus on the mathematical techniques for performing convolution. In the activity, students will practice convolution on mnist dataset examples we have set up. Students will use a script to use pooling and convolution for feature extraction and a script to perform classifications on the extracted feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs to many machine learning models consist of features or attributes of specific instances. In deep learning, raw data, which is data without selected features, are used as inputs. The deep learning algorithm is responsible for extracting the features itself, while it continues to learn as it is used. Deep learning methods are very important to image recognition and other image processing applications due to their ability to work on very large amounts of data efficiently. <br>\n",
    "<br>\n",
    "Convolutional Neural Networks (CNNs) are deep learning methods that process large data inputs to recognize specific local patterns. Convolution and pooling layers are used to reduce the input into something computationally easier without losing important features.\n",
    "As images are typically represented as matrices of pixels, classification of images involve outputting a label from an input image. This output can be produced through CNN, starting by examining low-level features (lines/curves/dots) and ending by examining higher-level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution finds features (such as “edges” in an image) by repeatedly multiplying a small “filter” matrix against the larger input matrix (the image) whilst moving the filter matrix across the input matrix. The result of the matrix multiplication is then “pooled” to reduce the data to a single value representing the whole of a rectangular region of the input image. For example, after multiplying by a filter to detect horizontal lines, a pooling step might take each 3x3 area of the input image and turn it into a single value representing the likelihood that there is a horizontal line in that portion of the image. Pooling thus __reduces the volume of data.__ <br>\n",
    "<br>\n",
    "Filters may be responsible for identifying features like a green line, a horizontal gradient, or a blue dot in an image; but they may also operate on features that are harder to describe or for which there is no obvious human description. Because the filter is applied all over the input image, convolution may be less sensitive to the position of the input image, but it can still be very sensitive to other qualities of the image such as overall brightness, orientation, colors, etc. This is why CNNs are often trained with images presented at multiple angles, saturations and exposures, yielding better performance when time to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution is the process of combining two signals to output a third signal. Convolution in CNNs combines an input matrix and a filter matrix to produce a feature map, as shown below<br>\n",
    "#### Figure 1: Convolution [3]\n",
    "![alt text](convalgo.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter (the smaller input) is multiplied by each value in the original matrix in order to determine the new value in the output matrix. The rest of the output is filled by sliding, also known as convolving, the filter around the image. A large number in the result (comparably) relates to a greater likelihood that the feature associated with the filter exists in this location. <br>\n",
    "<br>\n",
    "The output of convolution is called a *feature map*. The feature map is a matrix where large values represent the presence of the used filters associated features and small or zero values represent an absence of this feature in specific locations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling reduces the resolution of an image by representing it in a smaller matrix. In conjunction with convolution, pooling is responsible for down-sampling the outputted feature maps. The features of an image can be summarized in patches. Converting to a smaller representation helps reduce the size of the problem as subsequent layers can use smaller matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling vs Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple different methods that can be used to reduce the size of a matrix without losing the important details of the original matrix. For feature maps, the important details are in the presence of small or zero values, while the presence of large values tell us whether a feature exists in this space. Max pooling and average pooling are two common methods for fulfilling this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: Common Types of Pooling [5]\n",
    "![alt text](maxavgpool.png \"Title\") <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, max pooling reduces a subsection of the input, known as the pool size, to its single largest value;  whereas average pooling averages the values in the subsection (as shown above). Between the two, max pooling is more commonly used in CNNs, as it is less computationally challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks make use of both convolution and pooling. Convolution represents the input as feature maps, while pooling samples the feature maps to summarize by features. **A convolutional layer always comes first and is followed by a pooling layer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3: The Architecture of a Convolutional Neural Network [4] <br>\n",
    "<br>\n",
    "\n",
    "![alt text](cnnarc.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated convolutions allow you to go from detecting very low-level features to high-level features. For example, using a 3x3 filter we might find short (3 pixel) sections of horizontal lines. After max pooling these, a subsequent 9x9 filter might detect the presence of longer (27 pixel) horizontal lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why CNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs reduce the volume of data needing to be processed in later layers within the pipeline. They extract features that would otherwise use a deep neural network, which are larger in size and harder to train. Additionally, they are also potentially more explainable, as we can see what a horizontal lines detection filter is doing and understand how it works. <br>\n",
    "<br>\n",
    "CNNs have many applications today. The most common application is image classification software as it can identify multiple faces in an image and learn unique features. An example of this is facial recognition, which many of you may have encountered in Apple Photos, where images are sorted into albums by who appears in them or in Facebook's suggested taggings for photos. Lastly, CNNs are also easy to parallelize using GPUs, FPGAs or ASICs allowing for more rapid computation than a neural network that doesn’t have such a regular, repetitive process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs, like all machine learning algorithms, are subject to bias with input data. It is important to ensure that any training dataset includes a diverse set of all possible inputs. Otherwise, models can learn to prefer a particular group over another. *For example*, a hand-dryer with a camera in it trained to recognize hands cannot be trained on images of white caucasian hands alone, or a CNN trained to recognize people needs to be trained on people in wheel-chairs too. Machine learning models that are trained on biased or uniform training data learn to be biased models. Diversifying training data or selecting training data for fairness between particular groups can help to mitigate bias before it is formed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm Up Questions\n",
    "Solutions can be found at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Why do we use Convolutional Neural Networks? (select all that apply)\n",
    "a) The position of the object in the image to be detected can vary. <br>\n",
    "b) The size of an input image can be  too big for a simple neural network. <br>\n",
    "c) CNNs are computationally less expensive <br>\n",
    "d) CNNs are much cooler than a regular neural network :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) What is the main purpose of the Convolution Layer? (select one)\n",
    "a) To generate feature maps <br>\n",
    "b) To make the image discrenible <br>\n",
    "c) To ease the computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Find the value of the 1st row, 2nd column of the matrix resulting from average pooling (2x2) on the below matrix:\n",
    "![alt text](warm3.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Solutions can be found at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "### a)  Let there be a sample input matrix, A, and a filter, B, shown below. Find the output feature map.\n",
    "#### (You can assume the stride to be 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)  Once you obtained the feature map from part (a), we now need to pool it to reduce the number of parameters, which will shorten the training time while addressing any possibilities of overfitting. Using max pooling, try to find the pooled feature map. \n",
    "#### (You can assume a 2x2 window and a stride of 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Why must the depth of the input parameter and filter be the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "### a) In CNNs, we process the image in different layers, instead of doing it in a single layer directly. Could you think of a possible advantage this gives CNNs over other networks (e.g. a fully connected network)? <br>\n",
    "### b) How is the number of layers related to the size of an input image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "\n",
    "#### Make sure that you have all the \".py\" files given in the folder in your Jupyter directory!\n",
    "\"Shift + Enter\" through the below cells, the computation time should take no more than a couple minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing images from the mnist datafile.\n",
    "# Setting up the model.\n",
    "\n",
    "import numpy as np\n",
    "from conv import Conv3x3\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "import gzip\n",
    "\n",
    "f = gzip.open('t10k-images-idx3-ubyte.gz','r')\n",
    "image_size = 28\n",
    "num_images = 10000\n",
    "f.read(1)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "test_images = data.reshape(num_images, image_size, image_size, 1)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import labels from mnist datafile.\n",
    "\n",
    "f = gzip.open('t10k-labels-idx1-ubyte.gz','r')\n",
    "num_images = 10000\n",
    "f.read(1)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data=data[7:,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Images and Labels\n",
    "\n",
    "labels=[]\n",
    "images=[]\n",
    "for i in range(len(data)):\n",
    "    if(data[i]==1 or data[i]==0):\n",
    "            labels.append(data[i])\n",
    "            images.append(np.squeeze(test_images[i],axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST CNN initialized!\n",
      "--- Epoch 1 ---\n",
      "[Step 100] Past 100 steps: Average Loss 0.533 | Accuracy: 86%\n",
      "[Step 200] Past 100 steps: Average Loss 0.066 | Accuracy: 98%\n",
      "[Step 300] Past 100 steps: Average Loss 0.015 | Accuracy: 100%\n",
      "[Step 400] Past 100 steps: Average Loss 0.012 | Accuracy: 100%\n",
      "[Step 500] Past 100 steps: Average Loss 0.036 | Accuracy: 99%\n",
      "[Step 600] Past 100 steps: Average Loss 0.009 | Accuracy: 100%\n",
      "[Step 700] Past 100 steps: Average Loss 0.011 | Accuracy: 100%\n",
      "[Step 800] Past 100 steps: Average Loss 0.009 | Accuracy: 100%\n",
      "[Step 900] Past 100 steps: Average Loss 0.006 | Accuracy: 100%\n",
      "--- Epoch 2 ---\n",
      "[Step 100] Past 100 steps: Average Loss 0.002 | Accuracy: 99%\n",
      "[Step 200] Past 100 steps: Average Loss 0.012 | Accuracy: 100%\n",
      "[Step 300] Past 100 steps: Average Loss 0.002 | Accuracy: 100%\n",
      "[Step 400] Past 100 steps: Average Loss 0.002 | Accuracy: 100%\n",
      "[Step 500] Past 100 steps: Average Loss 0.012 | Accuracy: 100%\n",
      "[Step 600] Past 100 steps: Average Loss 0.003 | Accuracy: 100%\n",
      "[Step 700] Past 100 steps: Average Loss 0.003 | Accuracy: 100%\n",
      "[Step 800] Past 100 steps: Average Loss 0.006 | Accuracy: 100%\n",
      "[Step 900] Past 100 steps: Average Loss 0.003 | Accuracy: 100%\n",
      "--- Epoch 3 ---\n",
      "[Step 100] Past 100 steps: Average Loss 0.001 | Accuracy: 99%\n",
      "[Step 200] Past 100 steps: Average Loss 0.005 | Accuracy: 100%\n",
      "[Step 300] Past 100 steps: Average Loss 0.001 | Accuracy: 100%\n",
      "[Step 400] Past 100 steps: Average Loss 0.001 | Accuracy: 100%\n",
      "[Step 500] Past 100 steps: Average Loss 0.005 | Accuracy: 100%\n",
      "[Step 600] Past 100 steps: Average Loss 0.002 | Accuracy: 100%\n",
      "[Step 700] Past 100 steps: Average Loss 0.002 | Accuracy: 100%\n",
      "[Step 800] Past 100 steps: Average Loss 0.004 | Accuracy: 100%\n",
      "[Step 900] Past 100 steps: Average Loss 0.002 | Accuracy: 100%\n",
      "\n",
      "--- Testing the CNN ---\n",
      "Test Loss: 0.00537617376812\n",
      "Test Accuracy: 0.9983539094650206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from conv import Conv3x3\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "import gzip\n",
    "\n",
    "# We only use the first 1k examples of each set in the interest of time.\n",
    "# Feel free to change this if you want.\n",
    "train_images = images[:900]\n",
    "train_labels = labels[:900]\n",
    "test_images = images[900:]\n",
    "test_labels = labels[900:]\n",
    "\n",
    "conv = Conv3x3(8)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPool2()                  # 26x26x8 -> 13x13x8\n",
    "softmax = Softmax(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
    "\n",
    "def forward(image, label):\n",
    "  '''\n",
    "  Completes a forward pass of the CNN and calculates the accuracy and\n",
    "  cross-entropy loss.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  '''\n",
    "  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "  # to work with. This is standard practice.\n",
    "  out = conv.forward((image / 255) - 0.5)\n",
    "  out = pool.forward(out)\n",
    "  out = softmax.forward(out)\n",
    "\n",
    "  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "  loss = -np.log(out[int(label)])\n",
    "  acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "  return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "  '''\n",
    "  Completes a full training step on the given image and label.\n",
    "  Returns the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[int(label)] = -1 / out[int(label)]\n",
    "\n",
    "  # Backprop\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc\n",
    "\n",
    "print('MNIST CNN initialized!')\n",
    "\n",
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "  print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "  # Shuffle the training data\n",
    "#   permutation = np.random.permutation(len(train_images))\n",
    "#   train_images = train_images[permutation]\n",
    "#   train_labels = train_labels[permutation]\n",
    "\n",
    "  # Train!\n",
    "  loss = 0\n",
    "  num_correct = 0\n",
    "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "    if i % 100 == 99:\n",
    "      print(\n",
    "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "        (i + 1, loss / 100, num_correct)\n",
    "      )\n",
    "      loss = 0\n",
    "      num_correct = 0\n",
    "\n",
    "    l, acc = train(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "# Test the CNN\n",
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like we have some pretty high testing accuracies! - nice work :) <br>\n",
    "\n",
    "## Coding Question \n",
    "After running the code above, **list the number of images in the training set?** <br>\n",
    "*Hint: Look at the input databases!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Through this activity, we introduced and formulated the topic of Convolutional Neural Networks. By understanding concepts such as convolution and pooling, as well as the architecture of a CNN, we now have a better idea of how CNNs take in input images, assign importance to various aspects within the image, and be able to differentiate each one from another --  all leading to being able to better understand the sophistication of an image. <br>\n",
    "<br>\n",
    "In the real world, CNNs are heavily used by companies with large amounts of data, giving them an apparent advantage over their competitors. Obviously, the more training data one can feed into a CNN, the more robust the CNN will become when it comes time for use. Facebook and Instagram can use the photos of the billion users it has, Google can use its search data, and Amazon can use data from the millions of transactions that are processed each day.<br>\n",
    "<br>\n",
    "Now that you have understood Convolutional Neural Networks, you now know the magic behind it all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solutions to Warm-Up Questions\n",
    "1) Options A & B <br>\n",
    "2) Option A <Br>\n",
    "3) Value = 5\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions to Excercises\n",
    "#### Problem 1\n",
    "\n",
    "a) The feature map will be the below matrix:<br>\n",
    "![alt text](sol1a.png \"Title\") <br>\n",
    "As we slide the filter over the input matrix, we scalar multiply each corresponding element in the filter with the input matrix, resulting in a 3x3 matrix. \n",
    "<br>\n",
    "<br>\n",
    "b) The pooled matrix will be the 2x2 matrix shown below: <br>\n",
    "![alt text](sol1b.png \"Title\")\n",
    "<br>\n",
    "c) Depth translates to the different channels of the training images. Thus, when deciding on the dimensions of the filter, they must be equal to retain all characteristics of the input image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Since the CNNs have the files which extract features and are then subsequently pooled, the number of weights that are updated is significantly lower and thus less computationally expensive when it is divided into layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) As the image gets larger, we use more layers to make the process less computationally expensive, we use more layers. This is also referred to as a Deep Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to Coding Question\n",
    "The only two numbers being compared are 0 and 1. As both of those numbers are distinct in shape, the model does pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] A. Deshpande, “A Beginner's Guide To Understanding Convolutional Neural Networks,” \n",
    "*A Beginner's Guide To Understanding Convolutional Neural Networks – Adit Deshpande – Engineering at Forward | UCLA CS '19.* [Online]. Available: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/. [Accessed: 5-Dec-2019].\n",
    "<br>\n",
    "<br>\n",
    "[2] \tK. Vu, “Beginner's Guide: Image Recognition And Deep Learning - DZone AI,” \n",
    "dzone.com, 29-Nov-2018. [Online]. Available: https://dzone.com/articles/beginners-guide-image-recognition-and-deeplearnin. [Accessed: 5-Dec-2019]. <br>\n",
    "<br>\n",
    "[3]\tM. Basavarajaiah, “6 basic things to know about Convolution,” *Medium*, 02-Apr-2019. \n",
    "[Online]. Available: https://medium.com/@bdhuma/6-basic-things-to-know-about-convolution-daef5e1bc411. [Accessed: 7-Dec-2019].\n",
    "<br>\n",
    "<br>\n",
    "[4]\tS. Saha, “A Comprehensive Guide to Convolutional Neural Networks - the ELI5 way,” \n",
    "*Medium*, 17-Dec-2018. [Online]. Available: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53. [Accessed: 11-Dec-2019].\n",
    "<br>\n",
    "<br>\n",
    "[5]\tYani, Muhamad & Irawan, S, & S.T., M.T.. (2019). “Application of Transfer Learning \n",
    "Using Convolutional Neural Network Method for Early Detection of Terry’s Nail.” \n",
    "*Journal of Physics: Conference Series.* 1201.012052. 10.1088/1742-6596/1201/1/012052."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
